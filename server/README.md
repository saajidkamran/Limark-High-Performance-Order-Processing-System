# Order Processing Backend Server

A high-performance, scalable backend server built with **Fastify** for processing large batches of orders with idempotency, caching, and real-time streaming capabilities.

## üìã Table of Contents

- [Overview](#overview)
- [Why Fastify Instead of Express?](#why-fastify-instead-of-express)
- [Architecture](#architecture)
- [Core Features](#core-features)
- [Setup & Installation](#setup--installation)
- [API Endpoints](#api-endpoints)
- [Idempotency](#idempotency)
- [In-Memory Cache](#in-memory-cache)
- [Validation Layer](#validation-layer)
- [Processing Layer](#processing-layer)
- [Batch Processing Flow](#batch-processing-flow)
- [Middleware Architecture](#middleware-architecture)
- [Project Structure](#project-structure)
- [Testing](#testing)
- [Performance Considerations](#performance-considerations)

## üéØ Overview

This backend server is designed to handle high-throughput order processing with:
- **Batch Processing**: Efficiently processes thousands of orders in configurable batches
- **Idempotency**: Prevents duplicate processing using idempotency keys
- **Caching**: In-memory cache for fast order lookups
- **Real-time Streaming**: Server-Sent Events (SSE) for live order updates
- **Validation**: Multi-layer validation for data integrity
- **Stress Testing**: Built-in stress testing capabilities

## üöÄ Why Fastify Instead of Express?

### Performance Benefits

**Fastify** was chosen over Express for several critical performance reasons:

1. **2x Faster Request Handling**
   - Fastify uses a highly optimized JSON parser
   - Faster route matching with a radix tree router
   - Lower overhead per request

2. **Built-in Schema Validation**
   - Native JSON Schema validation support
   - Automatic request/response validation
   - Type-safe route definitions

3. **Better TypeScript Support**
   - First-class TypeScript support
   - Better type inference for routes and middleware
   - Compile-time type safety

4. **Async/Await Native**
   - Built from the ground up for async/await
   - No callback overhead
   - Better error handling with async hooks

5. **Plugin Architecture**
   - Lightweight plugin system
   - Better code organization
   - Encapsulation and reusability

6. **Lower Memory Footprint**
   - More efficient memory usage
   - Better garbage collection patterns
   - Optimized for high-concurrency scenarios

### Benchmark Comparison

```
Express:  ~15,000 req/s
Fastify:  ~30,000+ req/s  (2x faster)
```

For a high-throughput order processing system handling 10,000+ orders, this performance difference is critical.

### Code Example: Fastify vs Express

**Express (Traditional):**
```javascript
app.post('/api/orders/batch', (req, res) => {
  // Manual validation
  // Manual error handling
  // Callback-based
});
```

**Fastify (Our Implementation):**
```typescript
app.post('/batch', {
  preHandler: [idempotencyMiddleware, validateOrdersBatchMiddleware],
}, async (req, reply) => {
  // Type-safe request
  // Automatic validation
  // Async/await native
  // Better error handling
});
```

## üèó Architecture

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Client Request                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Fastify Server (Port 3002)                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Middleware Layer (Validation)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Idempotency Middleware                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Order Validation Middleware                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - ID Validation Middleware                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚Üì                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ            Route Handlers                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - POST /api/orders/batch                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - GET  /api/orders/:id                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - PUT  /api/orders/:id/status                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - GET  /api/orders/stream                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚Üì                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Service Layer (Business Logic)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Order Service                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Stream Service                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Stress Test Service                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚Üì                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Store Layer (Data Access)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - OrderStore (In-memory Map)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - OrderCacheStore (TTL-based cache)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - IdempotencyStore (Response cache)            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

```
Request ‚Üí Middleware ‚Üí Route ‚Üí Service ‚Üí Store ‚Üí Response
   ‚Üì         ‚Üì          ‚Üì        ‚Üì        ‚Üì        ‚Üì
Validate  Idempotency Process  Cache   Update   Stream
```

## ‚ú® Core Features

### 1. Batch Processing
- Configurable batch sizes (default: 100, max: 1000)
- Sequential batch processing for consistency
- Progress tracking and error aggregation
- Environment-based configuration

### 2. Idempotency
- Industry-standard idempotency key support
- Prevents duplicate processing
- Cached responses for retries
- 24-hour TTL for idempotency keys

### 3. In-Memory Caching
- Fast order lookups with cache hit/miss tracking
- TTL-based expiration (5 minutes default)
- Automatic cache invalidation on updates
- Cache age headers for monitoring

### 4. Real-time Streaming
- Server-Sent Events (SSE) for live updates
- Order creation and status change events
- Heartbeat mechanism for connection health
- Automatic cleanup on disconnect

### 5. Multi-Layer Validation
- Request shape validation
- Order structure validation
- Batch size validation
- ID format validation

## üöÄ Setup & Installation

### Prerequisites

- **Node.js**: v18.x or higher
- **npm**: v9.x or higher
- **TypeScript**: v5.9.3 or higher

### Installation

1. **Navigate to server directory**
   ```bash
   cd server
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set environment variables** (optional)
   Create a `.env` file:
   ```env
   PORT=3002
   HOST=0.0.0.0
   BATCH_SIZE=100
   ```

4. **Start development server**
   ```bash
   npm run dev
   ```

5. **Build for production**
   ```bash
   npm run build
   npm start
   ```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | `3002` | Server port |
| `HOST` | `0.0.0.0` | Server host |
| `BATCH_SIZE` | `100` | Default batch size for processing |

## üì° API Endpoints

### POST `/api/orders/batch`

Upload and process a batch of orders.

**Headers:**
- `Idempotency-Key`: Required. Unique key for idempotency (UUID or alphanumeric, 1-128 chars)

**Request Body:**
```json
[
  {
    "id": "ORD-10001",
    "status": "PENDING",
    "amount": 150.50,
    "createdAt": 1234567890,
    "updatedAt": 1234567890
  }
]
```

**Response:**
```json
{
  "success": true,
  "total": 1000,
  "processed": 950,
  "failed": 50,
  "batches": 10,
  "batchResults": [...]
}
```

### GET `/api/orders/:id`

Get order by ID with caching.

**Response Headers:**
- `X-Cache`: `HIT` or `MISS`
- `X-Cache-Age`: Cache age in seconds (if cached)

**Response:**
```json
{
  "id": "ORD-10001",
  "status": "PENDING",
  "amount": 150.50,
  "createdAt": 1234567890,
  "updatedAt": 1234567890
}
```

### PUT `/api/orders/:id/status`

Update order status.

**Request Body:**
```json
{
  "status": "PROCESSING"
}
```

### GET `/api/orders/stream`

Server-Sent Events stream for real-time order updates.

**Events:**
- `order.created`: New order created
- `order.statusChanged`: Order status updated
- `heartbeat`: Connection health check (every 30s)

## üîÑ Idempotency

### What is Idempotency?

Idempotency ensures that making the same request multiple times produces the same result. This is critical for:
- **Network retries**: Safe to retry failed requests
- **Duplicate prevention**: Prevents processing the same batch twice
- **Client reliability**: Clients can safely retry without side effects

### Implementation

#### 1. **Idempotency Key Requirement**

Every batch request **must** include an `Idempotency-Key` header:

```typescript
headers: {
  'Idempotency-Key': '550e8400-e29b-41d4-a716-446655440000'
}
```

#### 2. **Key Validation**

The middleware validates:
- Key exists (required)
- Format: 1-128 alphanumeric characters, hyphens, underscores
- Pattern: `/^[a-zA-Z0-9_-]{1,128}$/`

#### 3. **Response Caching**

When a request with an idempotency key is processed:
1. Check if key exists in `IdempotencyStore`
2. If found, return cached response immediately
3. If not found, process request and cache the response
4. Cache includes: response body, status code, timestamp

#### 4. **TTL and Cleanup**

- **TTL**: 24 hours (configurable)
- **Cleanup**: Automatic cleanup every hour
- **Storage**: In-memory Map (production: use Redis)

### Flow Diagram

```
Client Request with Idempotency-Key
           ‚Üì
    [Idempotency Middleware]
           ‚Üì
    Key exists in store?
    ‚îú‚îÄ YES ‚Üí Return cached response (same status code)
    ‚îî‚îÄ NO  ‚Üí Process request
                  ‚Üì
           Cache response
                  ‚Üì
          Return response
```

### Example Usage

```typescript
// First request
POST /api/orders/batch
Headers: { 'Idempotency-Key': 'abc123' }
Body: [1000 orders]
‚Üí Processes orders, returns result, caches response

// Retry with same key (network error, timeout, etc.)
POST /api/orders/batch
Headers: { 'Idempotency-Key': 'abc123' }
Body: [1000 orders]
‚Üí Returns cached response immediately (no processing)
```

### Industry Standards

This implementation follows patterns used by:
- **Stripe**: Uses idempotency keys for all POST requests
- **PayPal**: Idempotency for payment processing
- **AWS**: Idempotency tokens for API operations

## üíæ In-Memory Cache

### Purpose

The in-memory cache (`OrderCacheStore`) provides:
- **Fast lookups**: O(1) order retrieval
- **Reduced store access**: Minimize direct Map lookups
- **Performance monitoring**: Cache hit/miss tracking

### Implementation

#### Cache Structure

```typescript
interface OrderCacheEntry {
  order: Order;
  timestamp: number;    // When cached
  expiresAt: number;    // When it expires
}
```

#### Cache Operations

1. **Get**: Check cache, return if valid, otherwise fetch from store
2. **Set**: Cache order with TTL (default: 5 minutes)
3. **Invalidate**: Remove from cache (on updates)
4. **Cleanup**: Automatic cleanup every minute

### Cache Flow

```
GET /api/orders/:id
      ‚Üì
Check OrderCacheStore
      ‚Üì
  Cache Hit?
  ‚îú‚îÄ YES ‚Üí Return cached order + X-Cache: HIT
  ‚îî‚îÄ NO  ‚Üí Fetch from OrderStore
              ‚Üì
         Cache the order
              ‚Üì
      Return order + X-Cache: MISS
```

### Cache Invalidation

Cache is automatically invalidated when:
- Order status is updated
- Order is modified

This ensures data consistency.

### TTL Configuration

- **Default TTL**: 5 minutes (300,000ms)
- **Configurable**: Can be adjusted per cache entry
- **Cleanup**: Expired entries removed every minute

### Why In-Memory?

**Current Implementation**: In-memory Map
- Fast: No network overhead
- Simple: No external dependencies
- Suitable for: Single-server deployments, development

**Production Recommendation**: Redis
- Distributed caching
- Persistence across restarts
- Better for multi-server deployments

## ‚úÖ Validation Layer

The validation layer ensures data integrity through multiple validation stages.

### Validation Middleware Stack

```
Request
  ‚Üì
[Idempotency Middleware]     ‚Üí Validates idempotency key
  ‚Üì
[Validate Orders Batch]      ‚Üí Validates request shape
  ‚Üì
[Validate Order ID]          ‚Üí Validates ID format (for GET/PUT)
  ‚Üì
Route Handler
```

### 1. `validateBatchSize()`

Validates batch size using environment configuration.

**Location**: `src/validators/order.validator.ts`

**Function**:
```typescript
validateBatchSize(batchSize?: number): BatchSizeValidation
```

**Validation Rules**:
- Must be a number
- Minimum: 1
- Maximum: 1000
- Defaults to `BATCH_SIZE` env var or 100

**Returns**:
```typescript
{
  valid: boolean;
  error?: string;
  batchSize: number;  // Validated batch size to use
}
```

### 2. `validateOrder()`

Validates single order structure.

**Location**: `src/validators/order.validator.ts`

**Function**:
```typescript
validateOrder(order: Order): boolean
```

**Validation Rules**:
- `id`: Required, must be string
- `status`: Must be one of: `PENDING`, `PROCESSING`, `COMPLETED`, `FAILED`
- `amount`: Must be number, >= 0
- `createdAt`: Must be number, > 0
- `updatedAt`: Must be number, > 0

**Returns**: `true` if valid, `false` otherwise

### 3. `validateOrdersInput()`

Validates request body shape (middleware).

**Location**: `src/middleware/ordersValidate.middleware.ts`

**Validation Rules**:
- Body must be an array
- Array cannot be empty
- Each item must be an object
- Each order must have: `id`, `status`, `amount`
- Maximum orders per request: 1000

**Error Responses**:
- `400`: Invalid shape or missing fields
- `413`: Too many orders (exceeds MAX_ORDERS_PER_REQUEST)

### Validation Flow

```
POST /api/orders/batch
      ‚Üì
[validateOrdersInput] ‚Üí Check body is array, has required fields
      ‚Üì
[validateBatchSize]    ‚Üí Check batch size is valid (uses env config)
      ‚Üì
[processOrdersBatch]   ‚Üí Process orders
      ‚Üì
For each order:
  [validateOrder]      ‚Üí Validate order structure
      ‚Üì
  Process or reject
```

## ‚öôÔ∏è Processing Layer

The processing layer handles the core business logic of order processing.

### Core Functions

#### 1. `processOrder()`

Processes a single order.

**Function**:
```typescript
processOrder(order: Order): ProcessResult
```

**Steps**:
1. Validate order structure (`validateOrder()`)
2. Insert into `OrderStore`
3. Broadcast order created event
4. Return success/failure result

**Returns**:
```typescript
{
  success: boolean;
  order: Order;
  error?: string;  // If failed
}
```

#### 2. `processBatch()`

Processes an array of orders in a batch.

**Function**:
```typescript
processBatch(batch: Order[], batchIndex: number): Promise<BatchResult>
```

**Steps**:
1. Process each order in batch (`processOrder()`)
2. Count processed vs failed
3. Aggregate errors
4. Return batch result

**Returns**:
```typescript
{
  batchIndex: number;
  processed: number;
  failed: number;
  errors?: string[];  // If any failures
}
```

#### 3. `processOrdersBatch()`

Main entry point for processing all orders in batches.

**Function**:
```typescript
processOrdersBatch(
  orders: Order[],
  batchSize?: number
): Promise<BatchProcessResult>
```

**Steps**:
1. Validate batch size (`validateBatchSize()`)
2. Split orders into batches (`splitIntoBatches()`)
3. Process batches sequentially (`processBatchesSequentially()`)
4. Aggregate results (`aggregateBatchResults()`)
5. Return final result

**Returns**:
```typescript
{
  totalProcessed: number;
  totalFailed: number;
  batchResults: BatchResult[];
}
```

### Utility Functions

#### `splitIntoBatches()`

Splits array into chunks of specified size.

**Function**:
```typescript
splitIntoBatches<T>(items: T[], batchSize: number): T[][]
```

**Example**:
```typescript
splitIntoBatches([1,2,3,4,5,6,7,8,9,10], 3)
// Returns: [[1,2,3], [4,5,6], [7,8,9], [10]]
```

#### `aggregateBatchResults()`

Combines batch results into totals.

**Function**:
```typescript
aggregateBatchResults(
  batchResults: BatchResult[]
): { totalProcessed: number; totalFailed: number }
```

**Example**:
```typescript
aggregateBatchResults([
  { processed: 95, failed: 5 },
  { processed: 98, failed: 2 }
])
// Returns: { totalProcessed: 193, totalFailed: 7 }
```

#### `calculateProgress()`

Calculates progress percentage.

**Function**:
```typescript
calculateProgress(
  processedBatches: number,
  totalOrders: number,
  batchSize: number
): Progress
```

**Returns**:
```typescript
{
  processed: number;
  total: number;
  percentage: number;  // 0-100
}
```

## üîÄ Why Split Into Chunks?

Splitting large order arrays into smaller chunks (batches) is a critical design decision that provides multiple benefits:

### 1. **Memory Management**

**Problem**: Processing 10,000 orders at once can cause:
- High memory usage (all orders in memory simultaneously)
- Risk of running out of memory
- Poor garbage collection performance

**Solution**: Chunking processes orders in smaller groups:
- Only 100 orders in memory per batch (configurable)
- Constant memory footprint regardless of total order count
- Better garbage collection between batches

**Example**:
```
‚ùå Without Chunking:
Process 10,000 orders ‚Üí All 10,000 in memory ‚Üí High memory usage

‚úÖ With Chunking (batch size: 100):
Process 10,000 orders ‚Üí 100 at a time ‚Üí Constant memory usage
```

### 2. **Error Handling & Recovery**

**Problem**: If processing fails halfway through 10,000 orders:
- No way to know which orders succeeded
- Must restart from beginning
- Difficult to identify problematic orders

**Solution**: Chunking provides granular error tracking:
- Each batch reports success/failure independently
- Failed batches can be retried separately
- Clear visibility into which orders failed

**Example**:
```
Processing 10,000 orders in 100 batches:
- Batch 0-9: ‚úÖ Success (1000 orders processed)
- Batch 10: ‚ùå Failed (100 orders failed)
- Batch 11-99: ‚úÖ Success (8900 orders processed)

Result: 9900 processed, 100 failed
‚Üí Can retry only Batch 10
```

### 3. **Progress Tracking**

**Problem**: Processing 10,000 orders provides no feedback:
- No way to show progress to client
- Client doesn't know if server is working or stuck
- Difficult to estimate completion time

**Solution**: Chunking enables progress reporting:
- Track progress per batch (e.g., "Processing batch 5/100")
- Calculate percentage complete
- Provide real-time updates to clients

**Example**:
```
Batch 1/10: 10% complete
Batch 2/10: 20% complete
...
Batch 10/10: 100% complete
```

### 4. **Timeout Prevention**

**Problem**: Processing 10,000 orders might exceed:
- HTTP request timeout limits
- Server timeout limits
- Client connection timeouts

**Solution**: Chunking keeps processing time manageable:
- Each batch processes quickly (< 1 second)
- Can return partial results if timeout occurs
- Client can make multiple smaller requests if needed

**Example**:
```
‚ùå Single Request: 10,000 orders ‚Üí 30 seconds ‚Üí Timeout!

‚úÖ Chunked: 100 orders per batch ‚Üí 0.3 seconds per batch
   ‚Üí 10 batches √ó 0.3s = 3 seconds total ‚Üí Success!
```

### 5. **Database/Store Performance**

**Problem**: Bulk inserting 10,000 orders at once:
- Can lock the database/store
- Slow transaction commit
- Risk of transaction rollback on error

**Solution**: Chunking uses smaller transactions:
- Each batch is a smaller transaction
- Faster commits
- Less lock contention
- Better concurrency

**Example**:
```
‚ùå Single Transaction: INSERT 10,000 orders
   ‚Üí Long lock time ‚Üí Blocks other operations

‚úÖ Chunked Transactions: INSERT 100 orders √ó 10 times
   ‚Üí Short lock times ‚Üí Better concurrency
```

### 6. **Scalability & Resource Control**

**Problem**: Processing all orders at once:
- Consumes all available CPU/memory
- Blocks other requests
- No way to throttle processing

**Solution**: Chunking provides control:
- Process one batch at a time (sequential)
- Can add delays between batches
- Can process batches in parallel (future enhancement)
- Better resource utilization

### 7. **Debugging & Monitoring**

**Problem**: Hard to debug issues with 10,000 orders:
- Which order caused the problem?
- Where did processing fail?
- Performance bottlenecks unclear

**Solution**: Chunking provides granular insights:
- Track performance per batch
- Identify slow batches
- Isolate problematic orders to specific batches
- Better logging and monitoring

**Example**:
```
Batch 0: 95ms
Batch 1: 98ms
Batch 2: 1200ms ‚Üê Performance issue detected!
Batch 3: 97ms
...
```

### 8. **Flexibility & Configuration**

**Problem**: Fixed processing approach:
- Can't adjust for different scenarios
- One size doesn't fit all

**Solution**: Configurable batch size:
- Small batches (10-50): For complex validation
- Medium batches (100): Default balanced approach
- Large batches (500-1000): For simple, fast processing
- Adjustable via environment variable

**Example**:
```env
# Development: Smaller batches for easier debugging
BATCH_SIZE=50

# Production: Larger batches for better throughput
BATCH_SIZE=200

# High-load: Maximum batch size
BATCH_SIZE=1000
```

### Real-World Analogy

Think of chunking like **loading a truck**:

**‚ùå Without Chunking**: Try to load all boxes at once
- Overwhelming
- Risk of dropping everything
- Can't track progress
- If something goes wrong, start over

**‚úÖ With Chunking**: Load boxes in groups of 100
- Manageable
- Can track how many groups loaded
- If one group has issues, fix just that group
- Can pause/resume between groups

### Performance Impact

**Chunking Overhead**: Minimal
- Array splitting: O(n) - very fast
- Batch iteration: O(n) - same as processing all at once
- Result aggregation: O(batches) - negligible

**Benefits**: Significant
- Better memory usage
- Better error handling
- Better progress tracking
- Better scalability

### When NOT to Chunk?

Chunking is beneficial for:
- ‚úÖ Large datasets (100+ items)
- ‚úÖ Complex processing per item
- ‚úÖ Need for progress tracking
- ‚úÖ Error recovery requirements

Chunking may be unnecessary for:
- ‚ùå Very small datasets (< 10 items)
- ‚ùå Trivial processing (simple transformations)
- ‚ùå Atomic requirements (all-or-nothing)

## üìä Batch Processing Flow

### Complete Flow Diagram

```
1. processOrdersBatch([1000 orders])
      ‚Üì
2. validateBatchSize() ‚Üí uses BATCH_SIZE from env
      ‚Üì
3. splitIntoBatches() ‚Üí splits orders into chunks
      ‚Üì
4. processBatchesSequentially() ‚Üí processes each batch
      ‚Üì
5. processBatch() ‚Üí processes orders in batch
      ‚Üì
6. processOrder() ‚Üí validates & inserts each order
      ‚Üì
7. aggregateBatchResults() ‚Üí combines all results
      ‚Üì
8. Returns BatchProcessResult
```

### Detailed Example

**Input**: `processOrdersBatch([1000 orders])`

**Step 1**: Validate batch size
- Uses `BATCH_SIZE` env var (default: 100)
- Validates: 1 <= batchSize <= 1000
- ‚úÖ Valid

**Step 2**: Split into batches
```typescript
splitIntoBatches(1000 orders, 100)
// Creates 10 batches of 100 orders each
// Batch 0: orders[0-99]
// Batch 1: orders[100-199]
// ...
// Batch 9: orders[900-999]
```

**Step 3**: Process batches sequentially
```typescript
For each batch ‚Üí processBatch()
  ‚Üì
  For each order ‚Üí processOrder()
    ‚Üì
    Returns BatchResult { processed: 95, failed: 5 }
```

**Step 4**: Aggregate results
```typescript
aggregateBatchResults([
  { processed: 95, failed: 5 },   // Batch 0
  { processed: 98, failed: 2 },   // Batch 1
  { processed: 100, failed: 0 },   // Batch 2
  // ... 7 more batches
])
// Returns: { totalProcessed: 950, totalFailed: 50 }
```

**Step 5**: Return final result
```typescript
{
  totalProcessed: 950,
  totalFailed: 50,
  batchResults: [/* 10 batch results */]
}
```

### Why Sequential Batch Processing?

**Sequential** (current implementation):
- ‚úÖ Maintains order consistency
- ‚úÖ Predictable memory usage
- ‚úÖ Easier error handling
- ‚úÖ Simpler to debug

**Parallel** (future enhancement):
- ‚ö° Faster processing
- ‚ö†Ô∏è Higher memory usage
- ‚ö†Ô∏è More complex error handling
- ‚ö†Ô∏è Potential race conditions

For production, consider parallel batch processing with controlled concurrency.

## üõ°Ô∏è Middleware Architecture

### Middleware Stack

The server uses a layered middleware approach:

```
Request
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Idempotency Middleware          ‚îÇ
‚îÇ     - Validates idempotency key     ‚îÇ
‚îÇ     - Checks cache for duplicate    ‚îÇ
‚îÇ     - Returns cached response if found‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Validation Middleware           ‚îÇ
‚îÇ     - validateOrdersBatchMiddleware ‚îÇ
‚îÇ     - validateOrderIdMiddleware     ‚îÇ
‚îÇ     - validateStressTestMiddleware  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Route Handler                   ‚îÇ
‚îÇ     - Business logic                ‚îÇ
‚îÇ     - Service calls                 ‚îÇ
‚îÇ     - Response formatting           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
Response
```

### Middleware Details

#### 1. Idempotency Middleware

**File**: `src/middleware/idempotency.middleware.ts`

**Purpose**: Prevents duplicate request processing

**Flow**:
1. Extract `Idempotency-Key` from headers
2. Validate key format
3. Check `IdempotencyStore` for cached response
4. If found: return cached response immediately
5. If not: attach key to request for later caching

#### 2. Order Validation Middleware

**File**: `src/middleware/ordersValidate.middleware.ts`

**Purpose**: Validates request body shape

**Flow**:
1. Check body is array
2. Check array is not empty
3. Validate each order has required fields
4. Check order count <= MAX_ORDERS_PER_REQUEST
5. Attach validated orders to request

#### 3. ID Validation Middleware

**File**: `src/middleware/validateId.middleware.ts`

**Purpose**: Validates order ID format

**Flow**:
1. Extract ID from route params
2. Validate ID format
3. Return 400 if invalid

#### 4. Stress Test Validation Middleware

**File**: `src/middleware/stressTestValidate.middleware.ts`

**Purpose**: Validates stress test configuration

**Flow**:
1. Validate order count
2. Validate batch size
3. Validate concurrent batches (if provided)

## üìÅ Project Structure

```
server/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app.ts                    # Fastify app setup
‚îÇ   ‚îú‚îÄ‚îÄ server.ts                 # Server entry point
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts             # Configuration (batch size, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ idempotency.middleware.ts      # Idempotency handling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ordersValidate.middleware.ts   # Order validation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validateId.middleware.ts      # ID validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stressTestValidate.middleware.ts # Stress test validation
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orders.routes.ts     # Order routes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ system.routes.ts     # System/health routes
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ order.service.ts     # Order processing logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stream.service.ts    # SSE streaming
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stress-test.service.ts # Stress testing
‚îÇ   ‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ order.store.ts       # In-memory order storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ idempotency.store.ts # Idempotency key cache
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ order.store.ts   # Order cache with TTL
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ order.ts             # Order type definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ order.service.ts    # Service type definitions
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batch.utils.ts      # Batch processing utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.ts          # Performance metrics
‚îÇ   ‚îî‚îÄ‚îÄ validators/
‚îÇ       ‚îî‚îÄ‚îÄ order.validator.ts  # Order validation functions
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ README.md
```

## üß™ Testing

### Running Tests

```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch
```

### Test Coverage

The server includes tests for:
- ‚úÖ Idempotency middleware
- ‚úÖ Order validation middleware
- ‚úÖ Order service (processing logic)
- ‚úÖ Stream service
- ‚úÖ System routes
- ‚úÖ Store implementations

### Test Structure

```
server/src/
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îú‚îÄ‚îÄ idempotency.middleware.test.ts
‚îÇ   ‚îú‚îÄ‚îÄ ordersValidate.middleware.test.ts
‚îÇ   ‚îî‚îÄ‚îÄ validateId.middleware.test.ts
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ order.service.test.ts
‚îÇ   ‚îî‚îÄ‚îÄ stream.service.test.ts
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ system.routes.test.ts
‚îî‚îÄ‚îÄ store/
    ‚îî‚îÄ‚îÄ idempotency.store.test.ts
```

## ‚ö° Performance Considerations

### Optimization Strategies

1. **In-Memory Storage**
   - Fast Map-based storage for orders
   - O(1) lookup time
   - Suitable for high-throughput scenarios

2. **Batch Processing**
   - Configurable batch sizes
   - Sequential processing for consistency
   - Error aggregation for efficiency

3. **Caching**
   - TTL-based cache for frequent lookups
   - Automatic invalidation on updates
   - Cache hit/miss tracking

4. **Idempotency Caching**
   - Prevents duplicate processing
   - Reduces load on duplicate requests
   - Automatic cleanup of expired keys

5. **Efficient Validation**
   - Early validation (fail fast)
   - Minimal overhead per request
   - Type-safe validation

### Production Recommendations

1. **Replace In-Memory Stores with Redis**
   - Distributed caching
   - Persistence across restarts
   - Better for multi-server deployments

2. **Add Database Layer**
   - Persistent storage for orders
   - Better data integrity
   - Query capabilities

3. **Implement Rate Limiting**
   - Prevent abuse
   - Fair resource allocation
   - DDoS protection

4. **Add Monitoring**
   - Request metrics
   - Error tracking
   - Performance monitoring

5. **Consider Parallel Batch Processing**
   - For very large batches
   - With controlled concurrency
   - Careful error handling

## üìù License

[Add your license information here]

---

**Note**: This server is optimized for high-throughput order processing. For production deployments, consider replacing in-memory stores with Redis and adding a persistent database layer.

